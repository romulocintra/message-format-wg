13 February 2024 | MessageFormat Working Virtual Face-to-Face

### Attendees
- Addison Phillips - Unicode (APP) - chair
- Tim Chevalier - Igalia (TIM)
- Ujjwal Sharma - Igalia (USA)
- Eemeli Aro - Mozilla (EAO)
- Elango Cheran - Google (ECH)
- Mihai Niță - Google (MIH)
- Staś Małolepszy - Google (STA)
- Mark Davis - Google (MED)

Scribe: USA, TIM, ECH
Previous Scribe: MIH



## Topic: Progressing to Done

The main blockers appear to be the following:
- ~~Beautification of the syntax discussion~~
- ~~What’s in a name? (Does NCName fix our woes? Go to UAX31? what?)~~
- ~~Quoting~~
- ~~Format-to-Parts~~
- ~~Spannables~~
- ~~Expression Attributes~~
- Registry and default functions
- Implementation and testing


Schedule:
1. No new LDML45 issues after 15 January.
2. All LDML45 issues resolved by end of F2F. Balloting alpha spec to occur 15 February.
3. Beta spec and registry by 11 March.
4. Can make limited changes thereafter, for issues discovered by implementers.
5. Release 10 April as part of LDML45

## Topic: Allow Options on Closing Markup Placeholders
This is the last potential change to the syntax in the LDML45 release. We will have a time-boxed discussion of whether to include closing markup placeholders. If necessary we will ballot this change.

STA: The current state is that markup is a special feature that’s only allowed inside patterns. Open and standalone tags can take options but close elements can’t, following XML. This PR opens up that restriction. Everywhere in the syntax, options are allowed except for the closing elements which have various cases in which they could use these options. EAO has mentioned that these use cases are similar and they’d benefit from the ID option so he proposed a workaround. Currently there’s no alternative for this ID use case.

MED: If someone’s using another type of markup, they could make use of it.

STA: HTML doesn’t have it and it’s well-formed so it’s possible to know which closing tag corresponds to which opening tag but in some cases like markup for Android, well-formed-ness isn’t imposed.

MED: This is already up to which binding you use. It can be used for HTML but also for non-HTML markup elements.

EAO: I’d suggest solving this by an @id attribute. I’m not aware of anyone having presented any use cases that don’t just deal with this case so I’m unwilling to open this up without a more diverse set of uses.

STA: The alternative of using expression attributes would be to just allow options here. It’s adding a known concept to an existing element whereas we’re not even at a stage where we’ve defined expression attributes.

MIH: I concur with STA. I think we brought examples, I just think EAO doesn’t find them convincing but I can show more examples where open and close tags share all the attributes, not just IDs.

APP: A couple of quick points:

As with other things, we’re agnostic to markup languages.
…
As with XLIFF, different elements could mark the beginning and end and while both sides have attributes since they’re dissimilar we can implement them using standalone tags
MED: There’s a lot of constraints in HTML and XML apart from this one so I’d be perfectly fine with this.

EAO: I give up, clearly I’m not convincing you all so let’s just focus on education. It’s a bit unfortunate that we’ve settled on this solution because it’s so vaguely done which is okay but not ideal. Would be willing to review the spec.

APP: This applies to any option you specify, though.

EAO: I’m talking about the most popular use case presented which was to connect open and close tags but it’s not actually well-defined how that’s handled.

MED: It’s perfectly normal  to caution that these won’t be used when expressing markup in HTML and XML. That said, right now I don’t think we should go overboard with warnings.

USA: what eemeli just mentioned, as long as this is the syntax space is open, whatever the underlying markup flavor is. If its the same id tag or what, that would be determined on the markup layer, not in our agonistic markup

MIH: If you look at XLIFF, it’s not just IDs, it’s a lot more things.

APP: #582 has a quote of the ABNF from the spec and some text. Is this sufficient for us as a starting point? Do we need to review it?

EAO: We need the action item for someone to write the spec for it, this is still the design doc.

## Topic: Data Model (#633, #632, #582)
Given choices in the Intl.MessageFormat space, we should pay reasonable attention to ensuring the data model describes “formatted messages” in an appropriate way. However, since the data model is non-normative, this seems like a task best suited for the Tech Preview period. Let’s discuss how much attention to give this in the current release.

APP: We have multiple PRs open against the data model. We have an agreement that the data model is a reference data model and that it is.

EAO: This particular aspect is one where we might not be entirely aligned. I’ll read out the intro to the data model we currently have.

APP: A previous decision we took was to make it non-normative. In fact, the text says you’re not required to implement it. It might be useful for the type of interchange that you’re talking about.

STA: I always thought this intro was phrased a bit weirdly, but let’s talk about. We agree that the data model is not normative and that it’s not a deliverable. We explicitly removed it from the list.

APP: It’s a formally defined deliverable in our WG charter.

STA: But the deliverable says “canonical” which isn’t exactly the reference data model but we could discuss it. We might have some misunderstanding. In my opinion interchange is in the context of tooling, this is why XLIFF is called XLIFF. I guess I can imagine different syntaxes could be equivalent but this isn’t my understanding for now. The data model to me is what the syntax looks like after being parsed.

APP: We should have a discussion about whether we need to dedicate time on this for 45. I believe that our previous discussion was that you can write MF2 implementation that took our syntax and was testable and such without ever worrying about the data model. That’s why we didn’t normatively require implementations to accept it. That said, the new info EAO presents makes a strong case for reconsidering it here.

EAO: The way we portray it and the way we talk about it in the deliverables is different. One way to do this is to define what’s a canonical format, we have this interchange format, how do they derive from each other.

MED: I can see the need for ECMA to want a concrete data model. I don’t think other implementations would necessarily need it though. The question is, if I have an implementation that implements the syntax and the spec and produces the results it should, should it expose an external data model? What should we do in this time frame? So far in this project it’s been rather unrealistic to think of a concrete data model in 45. We should decide how to expose the data model in 46 and what to communicate about it in 45.

STA: Thanks Mark. I agree that we decided to focus on the syntax because we were confident we could guarantee stability. If we want to guarantee a similar level of stability for the data model, we’d have to go through a similar time consuming process. I’d also argue that we should pen down as a design doc what we need in terms of the data model.

MIH: IMO as long as the main use case is not interchange and then it’s not as big of a deal. The most important aspect is that implementations can wrangle with it, I’ve heard from Java MF developers the benefits of the data model but then again it doesn’t mean you can directly use it elsewhere. It’s just a handy feature for tooling.

APP: I slightly disagree with some of the comments made about the correlation between the data model and the syntax. The reason we were confident about the data model is because the stability flows from the syntax. I think it can describe everything and it can be improved in the future by expansion. I’d be against calling the data model inadequate. The big question is, how important is it as a deliverable?

MED: I like Elango’s description of what he’s looking for which explains the desire on the TC39 side. I’d like to have a data model which is translatable back and forth between the syntax and they’d give you the same results. … I’m leery about saying that there’s the data model and you have to conform to it in a particular respect. I’m fine with saying “here’s a data model and this data model can be used even for representing / passing into an API, for languages that like this kind of thing.” I’m not there about saying that in order to implement MF, you have to implement this data model, b/c I don’t think that’s something we want to require of all implementations. Many implementors would react negatively.

APP: I buy all that. I think the data model itself, absent some technical tweaks, is something we can reasonably deliver. It should – to Mark’s description – flow to/from the syntax pretty well. Doesn’t need to do anything but that in order to be a successful data model. For MF2 it would be nice if it had additional… but it doesn’t need to. It sounds like what we’re arguing about is the introduction to the section. We should decide what we want to say about the data model, if anything, other than “here is a data model that is consistent with our syntax.” The normativity would be that implementations are not required to implement it in order to be an MF2 implementation. We might want to have normativity from the POV that if you claim to implement the data model, that it looks like this. Internal normativity of the data model.

MED: And we can definitely do that; we do that a lot in Unicode. We say that if you claim to implement this, you do it this way. The question is whether we want to say that this is the data model and is the only one we’ll ever stamp as being a valid data model for MF, or whether we want to say that this is data model number 1.

STA: I like this thinking about non-normative data model; the primary use case I have been thinking about for the data model is that it’s convenient to have this canonical representation so everyone can agree about things they use and how they’re called and supposed to be used. Then they can also write tooling that can consume these representations and do interesting things with them. However, these representations are not necessarily – they’re not required for an implementation to be conformant, and they are not the internal representation. I’ve always thought about this as: implementations represent messages somehow, but can also print a canonical data model. So you can write AST visitors and transform messages somehow. Pluggable ecosystem of tooling. My other comment is to Elango’s comment – Elango was talking about the logical structure and how the data model represents it. I agree, but the problem is that data models exist in an implementation-specific manner. Some languages have maps, others don’t. If we want to say that a message is a map of variants, we need to make these decisions, or come up with some abstract way of describing this data model. Maybe some languages will drop fields… others will use monadic option types. Each implementation will end up representing the same concepts and names slightly differently. They will be easily convertible, but not exactly compatible with each other. Elango mentioned data literals… I’m concerned – we’re not converging on a single representation, which is the stringified message, in this world. Leads to fragmentation: JS uses one thing, Clojure uses something else, etc. The benefit of a standard comes from everyone using the same string syntax, the one we have. That’s where the compatibility comes from.

EAO: to Mark: we are all aligned on not requiring an implementation to provide a data model API, or effectively we are agreed that in a final MF2 spec, we are going to say something very similar to what we currently say in the data model text, which is that you’re not required to implement this, but we are defining this – what is a valid data model for the MF2 syntax. And that we are presenting it also in a way that allows for separate implementations to communicate with each other, possibly about messages, using this data model, should they have a need to do that beyond, for instance, the textual representation. For which I think there are absolutely use cases, and I do believe we ought to support them. But I don’t think we’re ever going to make this a required part of an implementation that claims to be a MessageFormat 2 implementation.

APP: I agree with all of that, therefore, the thing we need to decide is: what are we going to invest in this thing for 45? What do we need to do? I think it’s at least important enough to ensure that the data model we have is consistent with the syntax we have, and we should review that the details match up and naming is correct. I view the data model as being downstream of the syntax. Changes we make in the syntax are reflected here, not the other way around. I propose we consider some text in the document that clarifies the status and our intentions w/ the data model. I think we could assign that to Elango or Eemeli and could do a really good job in describing the point and purpose of the data model. Have a review to make sure it’s complete, then I propose we would somewhat table this other than veracity with the syntax. It’s not necessary in order for us to deliver our core deliverable, which is to let people write messages.

MIH: I thought a little over the break; I think my position on “not an interchange thing” may be too strong. It will probably be an interchange for something like JS. If ECMAScript decides, let’s take this JSON implementation and make it required for the browsers, it will be in that tech stack. Not on us to decide that that’s how it’ll look in JSON. The messaging from us to ECMA and other groups like that, XLIFF or whatever, is that this is stable. It’s not like we’re going to change it willy-nilly. Will make it as stable as we can; not currently set in stone b/c we’re not done. Can still tinker a little, extension points like we have extension points in the syntax so it can grow a little, but that’s where I was at.

EAO: Is everyone cool – Tim wrapped it up as Postel’s law, being relaxed on what you accept but strict on the output that you make. Including a statement like this in the data model text might satisfy both me and STA without getting into the technical details we’ve been arguing about. Resolving that would be nice. STA, would you be ok with me adding to the branch your PR is on, making this sort of statement?

STA: IIUC, this would mean for the question of optional arrays, an API can accept a JSON without the field, but if I’m writing an AST transformer, then I expect the API to return an empty array? I think that’s reasonable for JS, not sure what it means for typed languages. I think it means the native representation will be an “option” type. 

EAO: But the native representations are not covered by this explicitly.

STA: Maybe this is also a reason why we’re revolving around this topic. There is the data model and the serialized data model, and we may be confusing the two.

MED: I think the most important part of this is determining what we think of as the stability requirements we’re going to have. In tech preview we want to try to be really stable but we can make tweaks in response to feedback. Once we actually launch, we want to say that we won’t make any changes to the syntax that are not backward compatible. If we talk about the data model, and it’s an important thing that STA talked about, it’s very different – the JS syntax of the serialization, vs. the data model as a set of APIs that conceptually return the pieces. For that, I think we need a similar sort of stability, backwards compatibility. It can be extended in the future, but we won’t make this API reboot your machine.

APP: I made a proposal for what to do pragmatically. How do people feel about that? Fix the intro and check the current data model for veracity? I do think stability is an important consideration. I believe that we’ve actually – EAO has – done a reasonable job setting up the data model to be stable, with the extension points visible, because we’ve reserved some syntax pieces here and there and they’re all visible in the right way. Is that how we’d like to address this?

(Yes)

APP: anyone think that’s a bad idea?

STA: I think we should do what you suggested, but I’m also curious about how important JSON is to all of this. Maybe what we’re struggling with is that there’s the set of APIs and data structures and concepts, and then there’s a transformation to input JSON and output JSON, what EAO is talking about. But JSON is just one representation of these concepts. 

APP: Well, we have a TS one and then JSON and a DTD representation of those

STA: But when we say we’ll be lenient in accepting input, we can have multiple JSON schemata, showing what’s optional.

MED: If we want to, we can say “this is the official MessageFormat 2 JSON data model specification.” We can just lock it completely down and say this is it, and if you want to conform to this JSON data model, you have to follow what’s specified here. We have the freedom to do that if we think it will be useful.

EAO: So we could also – express the DTD and the JSON schema data models as being, these are the things you should be accepting, and then have the TS representation as the canonical “this is really the whole thing.”

STA: But you’re still not required to do it that way, you can hold it in memory whatever you want…

EAO: Yes. Can we also get parallelism between the JSON schema and the DTD? This sounds like an action point for me to pile onto STA’s PR so we can do these changes as one package. I think the attributes discussion is a separate discussion from what we’ve just been having. Separate action point is reworking or adding to the intro to the data model something about what we just discussed. A third action point is to re-review, maybe, the validity of the data model to represent the concrete syntax. Was there a third one?

APP: Can we put those together? Re-spin the intro and review for veracity?

EAO: I’ll take on the stuff about piling onto STA’s PR. I’ve written the intro as it stands and I think it’s a good representation of the syntax and how it all works. I don’t think I’m qualified to do the checking.

APP: I would nominate ECH but he’s taking a break. I will copy him and assign myself for now. How about reviewing for veracity? MIH, you’ll make a change when you do close options. Would you have time to include that?

MIH: What exactly?

APP: When you make the change to add options to close markup in the data model, review the other pieces to check consistency with the concrete syntax?

MIH: Just everything related to the closing attributes?

APP: I’m suggesting expanding it to look at the whole data model? I’m looking for a code review of the whole data model.

MIH: I’m fine with it, since I’m working on the ICU implementation right now. I just won’t collapse it in the same task with the closing thing

APP: I’ll make you a separate issue to track it.

EAO: I remembered one more thing, which MED mentioned. Making sure that the data model is covered by a stability policy. Define one that covers all bits of it, relevant parts should mention data model.

APP: Yes, that’s important. I will assign myself that.

EAO: I can probably work on the text update if you want, if you file an issue for it.

STA: Same rules as for the syntax and tech preview?

EAO: Yes

APP: Yes, we won’t pour concrete around something that could be influenced by other changes.

EAO: Related to that is whether we include attributes in the data model or not.

STA: And also maybe we can have a bit of a tactical discussion about whether and how we’d like to talk to TC39 about this. But after the changes land that we just assigned action items for.

APP: I think anything in our syntax needs to be in the data model. May not be described in the way we intend to use it later, but if you write a valid message and you break that message into a data model, it should reserialize as itself, modulo optional whitespace. Attributes are there, reserved, don’t do anything, but they will in the future and so they shouldn’t disappear when you parse. Will be important later b/c someone could hand you a data model and you implement attributes. We might constrain them more later. I think that’s one thing. Our discussion with TC39 is more going to be on the side of “this is lovely and you can have your stage 2 and so on, but realistically unless – the reason we’ve invested so much effort in the syntax is that’s where the action is. If you don’t have a syntax, you don’t have a formatter.” Providing 500 kinds of syntax is the problem we have now. We’re trying to create a harmonious thing across many implementations, and we really wish that you would buy into our syntax at an appropriate point in time, and make a commitment. We need to dominate the user space to do that.

EAO: For the Intl.MessageFormat discussions, there are two places where interested participants may continue this conversation outside of this WG. One is the GitHub repo for the proposal, which is the async place for these discussions. The next place where this proposal, and specifically the change to it of removing syntax support – will be replaced at next week’s TC39 TG2 meeting. That’s the group in charge of internationalization for the TC39 Intl object. ECMA-402, effectively. There’s a monthly call for that and on next Thursday, this is on the agenda. STA if you’re interested in participating, talk to Shane Carr about making sure you have an invite, and join the call. The GitHub repo is completely open and welcomes contributions. The challenge in convincing TC39 in general to accept the syntax – the pushback is from a few members who are not so active necessarily on the ECMA-402 stuff. Their opinions on this are well-founded in their concerns and I have a hard time believing that a convincing argument can be made in this particular case, that they should be ok with this untested (from their point of view) thing being accepted earlier than they are comfortable with. You can find out who’s pushing back against this and backchannel with them, but good luck. 

STA: I completely agree that these are well-founded concerns. I just don’t see how the data model makes it any better. In fact, I see other issues with it. I want to talk about expression attributes. I think the reason we reserved the syntax is not for parsers to serialize it back, but so that old parsers can parse without error if we ever standardize expression attributes. That’s the only stated reason. We should say that no one should use the syntax for attributes, and if you use them, it’s your problem and they won’t be serialized back. We don’t want people to start giving them meaning as if they were private-use annotations. It’s reserved for forward compatibility of old parsers.

USA: I didn’t mean to talk about attribute expressions, but to go back to APP, I hold a similar view. I completely understand, with EAO, that there are various reasons for these folks to feel very strongly about something they haven’t worked on themselves, and have very strong opinions about them without what I feel is an accurate understanding of how we’ve been doing all of this. For instance, they raised the issue of development of alternate formats. If anyone has observed the amount of work we’ve put in to come anywhere near a working syntax… I don’t think they appreciate the amount of time and energy to come up with anything else. Obviously due to the structure of TC39, it might be complicated to get this point across, but if we could, I think that will be ideal. I think they’re thinking in terms of – a formatting sort of built-in that optionally has this syntax, rather than something built around the syntax.

MIH: My hope for ECMAScript – I understand that they’re not necessarily open to taking it as-is. But I hope once this gets into ICU, maybe ICU4X, and a JS implementation, maybe EAO’s current implementation, we can point to this and say it’s a Unicode standard, it’s working, and after a year or two they might hopefully take it. I’m a bit disappointed b/c we started this whole thing b/c JS didn’t have anything, and then it became a Unicode thing instead, but I hope they’ll adopt it on their own time, and it’ll be this thing and not inventing another syntax. That would be a pity.

APP: I think doing this at Unicode instead of JS is the right thing. I expressed to Shane and I’ll say it again: people should learn to write messages once in one syntax and have that knowledge be portable, have tools be portable, and that’s a super benefit. Having other syntaxes is definitely not our goal. It’s an anti-goal for us, and we aren’t ever going to consider that. If you want to make your own, I have an xkcd cartoon for you and everyone knows which one it is. I hope what we’re not doing is creating the 16th syntax of which there will soon be 17, 18, etc. That’s our goal and I hope we can be successful. Therefore I’m patient enough to say that if we have to prove it some, fine, but… prove the syntax, not interstitial things.

APP: On attributes, I slightly disagree with STA; we have things that are reserved, and when you parse them you should be able to get them back. We don’t just have “it parses into the null bucket and into /dev/null” because that means you can’t ever get that information back. I think the data model should represent all of the structures in the ABNF but not be any more opinionated about them than our spec is currently. If you hand us an attribute, it doesn’t disappear, but it doesn’t mean anything per current spec. In the future, the attributes could have meaning and could be checked. But that’s interpretation of the data model, not changing its contents. Will contribute to stability of the data model, which is important.

EAO: I thought I’d mention – we talk about not wanting to support multiple syntaxes. I want to expressly say that we are currently in a situation where the world is quite full of different syntaxes for message formatting. To move towards an MF2 world, we can’t just give it and expect transition to happen. We need intermediate steps like a uniform data model representation that you can parse anything into. The data model enables much easier transitions to happen between the current world and what we want to be the future. I went and wrote a separate JS parser for MF2 and thus one takes the syntax and produces a data model; it only does syntax checks b/c the Intl.MessageFormat impl will do data model checks. When you minify and compress it, it’s 2KB of JS, which is an annoying tax but maybe low enough that people will be OK paying it. My gut feeling is that it’s performant enough that it’s on the edge of what’s achievable with JS in this sort of space. Annoying, but will be there for a while for Intl.MessageFormat. I think we’re supposed to be talking about expression attributes… not sure…

STA: Having two conversations at the same time. About attributes – but do you first want to finish TC39?

APP: I think we understand where we’re at with TC39. The most important thing we could do for that is deliver this week. We will then have the opportunity to demonstrate that things work and recruit people – to EAO’s point, not stop with “here it is!” but also implement and promote adoption as the way forward.

STA: Also, stage 2 is only 2 out of 4, right? The timelines might actually align for some sort of adoption once we see implementation in ICU. Before we get to discussing stage 3, for example, there might already be a year worth of experience in ICU. These things move at their own pace. Also about expression attributes, but I can pause and re-queue.

EAO: I’m optimistic that in the first proposal for TC39, deleting the syntax will make progress much faster. I don’t know how it’ll go, but I’ll be pushing it.

STA: I think it’s risky to go only for the data model. Maybe the value to be had is that thanks to the data model workaround, you can advance to stage 2 and by the time you’re ready to advance to stage 3, everyone will agree that the syntax is stable enough. Maybe just a bridge solution. That’s what I’m trying to ask for – that you will also advocate for it to be only a bridge solution, make it explicit. Stage 2 is ok without syntax but Stage 4 is not.

EAO: For that conversation, you should come to next week’s ECMA-402 call

STA: But what do you think?

EAO: My thinking is that I want all of this to advance and I don’t see a danger, as you put it, in advancing the data model first before the syntax. Currently the JS ecosystem for localization is very fragmented, we have multiple syntaxes, and providing some uniformity would be a step towards a better world. One thing that should be clarified: the data model support was always included in the Intl.MessageFormat proposal. It’s been there for two years. The current change is about dropping syntax support, not replacing it with data model support. 

APP: I don’t think we misunderstand, and it’s not bad or anything, it’s just that understandably, as a WG we have an interest in promoting a harmonious syntax b/c we think it’s the right interface. I agree with you in some ways; there will be other fronts to advance on. You’ve talked about Message Resource, DOM localization, and if a bunch of things use the syntax, that will contribute to being able to incorporate into TC39. I don’t want to over-rotate on them b/c I think we can win the technical argument later. Also, our data model is a poison pill in a way because it represents our syntax well. Other syntaxes can be translated into it, you can probably do stuff to make a badly localized MF1 message work, but it requires effort to use other syntaxes and our syntax will naturally work.

EAO: One challenge that does remain with those tasks that you mention is that the status of message resources is not fully clear. Getting that clarified would help a lot of things. It’s unrelated to LDML 45 but is hampering some other forward progress. If it is problematic to define message resources under Unicode, then it would be useful to know that. 

APP: They are out of scope, but it’s a significant interest. Why don’t you and MED and I find a little time to chat about this and how to forward it in Unicode.

STA: I wanted to disagree with you, APP, a little on expression attributes. I think we should actively discourage people from using other reserved keywords and syntax. We won’t make parsers error on them. But parsers should warn, and people should not learn to rely on reserved syntax. Perfectly valid to expect that parsers will drop reserved syntax. I would want the data model to not include reserved syntax at all. I realize our stability policy doesn’t say this. When we unreserve it, it might mean something else. We only make promises in stability policy, we make no demands.

APP: We say in the spec, don’t use this thing.

STA: I don’t think we say that explicitly.

MED: In this release, can I have namespaced options on a ___.

APP: Yes. We envisioned that you could use it for skeletons.

MED: And you could use them for grammatical case.

APP: `:icu:person` could format person names.

MIH: Regarding attributes, I don’t see a good use for them. Whatever you can do with them, you can do with standard functions. We can put these options in the registry for a function. There is no need for a different concept and syntax for that.

APP: This is a discussion that we’ve had before. EAO and I said that attributes are a way to reuse shared sets of options globally. We didn’t reach an agreement, and that we could come back to this in the timeframe after the CLDR v45 release. We’ve reserved the syntax only, for now. STA’s question about whether they are transitory through the syntax is a good one. If so, then we can file a PR to remove them from the syntax.

STA: I already filed a PR to remove them.

APP: The syntax will be in our syntax forever. We don’t have to implement them. It can be a free extension point that we may never utilize.

MIH: If we include this feature in the syntax, then we should include them in the data model. But if we don’t include this feature, then we should not include them.

EAO: Regarding the idea of “reserved” as a designation for syntactic parts, it creates a situation where _____.
Regarding attributes, I’m okay with dropping them from the data model. I am okay right now since they are still represented in the syntax, and we can discuss later about whether to remove attributes from the syntax

TIM: I agree with MIH that the attributes should be kept in the data model. It allows us to parse a MF string, and then being able to serialize it back to string while preserving that information.

MED: I’ll tell you a story. We reserved many code points in the Unicode standard. A separate encoding standard wanted to encode new characters using code points in the reserved space. That would have been very bad if it had proceeded, and we had to work with them to resolve the encoding of those characters. There is a problem with users to misinterpret “reserved” as fair use when it in fact should not be used.

STA: I am a little bit confused about the role of the data model in all of this. Once we un-reserve any of these sigils, we will need to change the data model. We lump them into the “unsupported data node” at that point. How do we deal with them in the future?

APP: There is a reason for that. If you use the MF 2.0 data model, then they are grouped as “unsupported data node”. If we unreserve one of the sigils in a future 2.x version, then we they would be captured by an existing production in the grammar. But we won’t drop it on the floor. And that’s the point of the data model, it prevents us from dropping things on the floor and defines what we support.

STA: We cannot guarantee the stability of the data model.

APP: No, we can’t. But we can ensure that the data model and the syntax are internally consistent. The same message ought to be able to be parsed into either data model. If you are a 2.0 implementation and someone sends you a 2.1 data model, then you fail on the parts that are new and unknown to you.

MIH: Yes, you have to change the data model to support (un-reserve) previously reserved stuff.

STA: What we’re talking about is what data model should represent. I think it should be something that represents canonical input data, so you can parse a message string into the data model and be able to reserialize it with no loss. However, I don’t think reserved syntax elements belong because they are not a canonical part of the syntax/spec, so they should not appear in the data model, either.

MED: I don’t see how to deal with this properly until we have reserved keywords. If we introduce something like `.match`, it would be hard to parse that and put it into the data model. Do you we just preserve that as a string?

APP: MIH pointed out that you can have a wall of garbage between an expression and a string.

TIM: see line 59 in the ABNF grammar: https://github.com/unicode-org/message-format-wg/blob/main/spec/message.abnf#L59

MED: I’m wondering about the principle that was articulated that you should be able to translate the message string into a data model losslessly including the reserved stuff.

APP: We do have productions that preserve them as a blob. So we can recover them. Even though we don’t give a precise production that confers specific meaning to them.

MED: It sounds like all of the reserved stuff has correspondence in the data model. So is there nothing to do?

STA: They all end up as a single node in the data model.

EAO: We’re waiting for clarification on whether we accept STA’s PR to remove reserved things from the data model.

STA: I think the blocker / dependency on this is what is the purpose of the data model.

APP: I propose that the data model should, to the degree possible, capture all of the productions. The normative text is that we say “don’t do anything with these ___ ones”. That would suggest that we don’t accept your PR, and instead address it in other ways.

STA: Let me think more about this.

EAO: Do we want to reserve all single-charaxter namepsaces for everything?

APP: I have a preliminary PR about this. I want to propose that there is one single namespace that we maintain for our functions.

APP: I’m a little reluctant. We’ve gone back and forth about this. We’ve talked about having ecosystem of pluggable functions, but that also removes standardized reusability in the way that emoji standardization has.

MED: We want at least one, so I’m in agreement with that. And there are a ton of single-character namespace.s

EAO: We also have the anonymous namespace, which we reserve for ourselves.

APP: I think we have to be cautious. The default registry defines something that everyone must implement. People might be unhappy if we define something that has a heavy data requirement. So we might have a 2-tier registry. And also for options, we might have functions that take skeletons in the `:q:skeleton` as the namespace for skelton-taking functions.

EAO: We haven’t concluded the attributes discussion. So we don’t have a feature that allows us to easily override the locale in the set of provided option values to a function.

APP: If we do that, we should allow that to happen in a consistent way.

EAO: How do we allow for overriding the locale? Can we not reserve the option?

APP: That would require us to then say that functions couldn’t use specific option names.

MED: What would that mean? That all functions would not be able to use an option called `lang`? What would they do, use the French word as the option name, `langue`?

MIH: I think the whole expression attribute space is so rough around the edges, so all we can say is don’t do anything with it. We may remove it in 2 months from now. If you ask me, we can remove it right now. We can put it back in if it’s useful, but after the CLDR v45 timeframe. It’s temporary, what we have is a tech preview.

APP: I admit that I am someone who would like expression attributes because I had a previous implementation that created this feature, and I would not have been happy to adopt MF2 from that and be stuck figuring out how to support my expression attribute feature. We should seek feedback in the tech preview.





## Topic: AOB?


MIH: Here is a list of attributes for XLIFF closing  tag
End of a spanning original code
<ec> : https://docs.oasis-open.org/xliff/xliff-core/v2.1/os/xliff-core-v2.1-os.html#ec
Start of a spanning original code
<sc> : https://docs.oasis-open.org/xliff/xliff-core/v2.1/os/xliff-core-v2.1-os.html#sc
Attributes (on both open / close): canCopy, canDelete, canOverlap, canReorder, copyOf, dataRef, dir, disp, equiv, id, isolated, subFlows, subType, type, attributes from other namespaces



APP: We have multiple PRs open against the data model. We have an agreement that the data model is a reference data model and that it is.

EAO: This particular aspect is one where we might not be entirely aligned. I’ll read out the intro to the data model we currently have.

APP: A previous decision we took was to make it non-normative. In fact, the text says you’re not required to implement it. It might be useful for the type of interchange that you’re talking about.

STA: I always thought this intro was phrased a bit weirdly, but let’s talk about. We agree that the data model is not normative and that it’s not a deliverable. We explicitly removed it from the list.

APP: It’s a formally defined deliverable in our WG charter.

STA: But the deliverable says “canonical” which isn’t exactly the reference data model but we could discuss it. We might have some misunderstanding. In my opinion interchange is in the context of tooling, this is why XLIFF is called XLIFF. I guess I can imagine different syntaxes could be equivalent but this isn’t my understanding for now. The data model to me is what the syntax looks like after being parsed.

APP: We should have a discussion about whether we need to dedicate time on this for 45. I believe that our previous discussion was that you can write MF2 implementation that took our syntax and was testable and such without ever worrying about the data model. That’s why we didn’t normatively require implementations to accept it. That said, the new info EAO presents makes a strong case for reconsidering it here.

EAO: The way we portray it and the way we talk about it in the deliverables is different. One way to do this is to define what’s a canonical format, we have this interchange format, how do they derive from each other.

MED: I can see the need for ECMA to want a concrete data model. I don’t think other implementations would necessarily need it though. The question is, if I have an implementation that implements the syntax and the spec and produces the results it should, should it expose an external data model? What should we do in this time frame? So far in this project it’s been rather unrealistic to think of a concrete data model in 45. We should decide how to expose the data model in 46 and what to communicate about it in 45.

STA: Thanks Mark. I agree that we decided to focus on the syntax because we were confident we could guarantee stability. If we want to guarantee a similar level of stability for the data model, we’d have to go through a similar time consuming process. I’d also argue that we should pen down as a design doc what we need in terms of the data model.

MIH: IMO as long as the main use case is not interchange and then it’s not as big of a deal. The most important aspect is that implementations can wrangle with it, I’ve heard from Java MF developers the benefits of the data model but then again it doesn’t mean you can directly use it elsewhere. It’s just a handy feature for tooling.

APP: I slightly disagree with some of the comments made about the correlation between the data model and the syntax. The reason we were confident about the data model is because the stability flows from the syntax. I think it can describe everything and it can be improved in the future by expansion. I’d be against calling the data model inadequate. The big question is, how important is it as a deliverable?



